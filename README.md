
---

# ğŸ¤– Autonomous Prompt-Based Company FAQ Assistant

A fully functional **Agentic AI assistant** that leverages **LangChain**, **OpenAI GPT**, and **FAISS** to answer company-specific questions from an internal FAQ file â€” all through an intuitive **Streamlit interface**.

---

## ğŸ“Œ Business Case

Organizations often maintain internal knowledge bases (FAQs, HR docs, IT policies). Manually searching through these can be time-consuming.

This assistant solves that by enabling:

* Fast, conversational access to FAQs
* GPT-generated human-like responses
* Zero need for manual rule-based systems

---

## ğŸ’¡ Features

* ğŸ”— Built with **LangChain RetrievalQA + OpenAI Chat Model**
* ğŸ’¬ Ask natural questions through **Streamlit**
* ğŸ§  Uses **FAISS vector search** over custom company FAQs
* ğŸ§¾ Loads Q\&A from `company_faq.csv`
* ğŸ” Secure API key handling using `.env`
* ğŸ› ï¸ Easily extendable to PDFs, DOCX, or enterprise databases

---

## ğŸ§ª Example Query

```text
What are the working hours?
```

â†’ The assistant retrieves the relevant document using FAISS and crafts a natural response using GPT.

---

## ğŸš€ Quickstart

### âœ… 1. Install dependencies

```bash
pip install -r requirements.txt
```

### âœ… 2. Add your OpenAI API key in `.env`

Create a file named `.env` in the root directory:

```env
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

### âœ… 3. Prepare the vector store (one-time step)

```bash
python src/model_training.py
```

This will:

* Load your FAQ CSV
* Create embeddings using OpenAI
* Save the FAISS index locally

### âœ… 4. Launch the assistant

```bash
streamlit run app/app.py
```

Your browser will open to a chat interface. Ask any question from your FAQ.

---

## ğŸ³ Docker Support (Optional)

You can containerize the assistant like this:

```bash
docker build -t company-assistant .
docker run -p 8501:8501 company-assistant
```

Make sure to pass your OpenAI key via Docker environment or bind the `.env` file.

---

## ğŸ“‚ Project Structure

```
Agents_autonomous_prompt_assistant/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py                  # Streamlit interface
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â””â”€â”€ company_faq.csv     # Custom company FAQs
â”œâ”€â”€ models/
â”‚   â””â”€â”€ vector_store/           # FAISS index + metadata
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent.py                # LangChain RetrievalQA loader
â”‚   â””â”€â”€ model_training.py       # Data â†’ embeddings â†’ FAISS
â”œâ”€â”€ .env                        # API key (not committed)
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
```

---

## ğŸ›  Tech Stack

| Component      | Description                                |
| -------------- | ------------------------------------------ |
| **LangChain**  | Framework for building LLM pipelines       |
| **OpenAI GPT** | Response generation via `ChatOpenAI`       |
| **FAISS**      | Local vector store for document similarity |
| **Streamlit**  | Frontend chat interface                    |
| **Pandas**     | Data ingestion and formatting              |
| **dotenv**     | Secure API key management                  |

---

## ğŸ”„ Future Enhancements

* Upload & ingest PDFs and Word documents
* Add memory for follow-up questions
* Track user sessions and chat logs
* Include source references or confidence scores

---
Let's Connect

Have questions or ideas for collaboration?

* [LinkedIn](https://www.linkedin.com/in/amitkharche)
* [Medium](https://medium.com/@amitkharche)
* [GitHub](https://github.com/amitkharche)

---
